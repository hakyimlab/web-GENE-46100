{
  "hash": "27d35319791eac3b95c7812ead602f80",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Enformer training\ndate: '2025-04-28'\ndescription: train enformer on human and mouse\njupyter: \n  kernelspec:\n    name: \"conda-env-enformer46100-py\"\n    language: \"python\"\n    display_name: \"enformer46100\"\neval: false\ncategories:\n  - gene46100\n  - notebook\n---\n\n\n::: {.callout-warning}\n# not yet tested locally\n needs data for training\n:::\n\n\nCopyright 2021 DeepMind Technologies Limited\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n     https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis colab showcases training of the Enformer model published in\n\n**\"Effective gene expression prediction from sequence by integrating long-range interactions\"**\n\nÅ½iga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, David R. Kelley\n\n## Steps\n\n- Setup tf.data.Dataset by directly accessing the Basenji2 data on GCS: `gs://basenji_barnyard/data`\n- Train the model for a few steps, alternating training on human and mouse data batches\n- Evaluate the model on human and mouse genomes\n\n## Setup\n\n**Start the colab kernel with GPU**: Runtime -> Change runtime type -> GPU\n\n### Install dependencies\n\n::: {#ca7b9476 .cell execution_count=1}\n``` {.python .cell-code}\n# %pip install dm-sonnet tqdm\n```\n:::\n\n\n::: {#c163fd0a .cell execution_count=2}\n``` {.python .cell-code}\n# Get enformer source code\n# !wget -q https://raw.githubusercontent.com/deepmind/deepmind-research/master/enformer/attention_module.py\n# !wget -q https://raw.githubusercontent.com/deepmind/deepmind-research/master/enformer/enformer.py\n```\n:::\n\n\n### Import\n\n::: {#82062336 .cell execution_count=3}\n``` {.python .cell-code}\nimport tensorflow as tf\n# Make sure the GPU is enabled\nassert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -> Change runtime type -> GPU'\n\n# Easier debugging of OOM\n%env TF_ENABLE_GPU_GARBAGE_COLLECTION=false\n```\n:::\n\n\n::: {#53ca29e2 .cell execution_count=4}\n``` {.python .cell-code}\nimport sonnet as snt\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\nimport numpy as np\nimport pandas as pd\nimport time\nimport os\n```\n:::\n\n\n::: {#af82d349 .cell execution_count=5}\n``` {.python .cell-code}\nassert snt.__version__.startswith('2.0')\n```\n:::\n\n\n::: {#1a489cce .cell execution_count=6}\n``` {.python .cell-code}\ntf.__version__\n```\n:::\n\n\n::: {#d49748a1 .cell execution_count=7}\n``` {.python .cell-code}\n# this doesn't work on mac os\n# !nvidia-smi\nprint(tf.config.list_physical_devices('GPU'))\n# There is no direct command-line equivalent to nvidia-smi for Apple Silicon. Use Activity Monitor for a graphical view, or check GPU availability in TensorFlow with Python code.\n```\n:::\n\n\n### Code\n\n::: {#2967c1f7 .cell execution_count=8}\n``` {.python .cell-code}\nimport enformer\n```\n:::\n\n\n::: {#1e5acff7 .cell execution_count=9}\n``` {.python .cell-code}\n# @title `get_targets(organism)`\ndef get_targets(organism):\n  targets_txt = f'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_{organism}.txt'\n  return pd.read_csv(targets_txt, sep='\\t')\n```\n:::\n\n\n::: {#38995c25 .cell execution_count=10}\n``` {.python .cell-code}\n# @title `get_dataset(organism, subset, num_threads=8)`\nimport glob\nimport json\nimport functools\n\n\ndef organism_path(organism):\n  return os.path.join('gs://basenji_barnyard/data', organism)\n\n\ndef get_dataset(organism, subset, num_threads=8):\n  metadata = get_metadata(organism)\n  dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n                                    compression_type='ZLIB',\n                                    num_parallel_reads=num_threads)\n  dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n                        num_parallel_calls=num_threads)\n  return dataset\n\n\ndef get_metadata(organism):\n  # Keys:\n  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n  # pool_width, crop_bp, target_length\n  path = os.path.join(organism_path(organism), 'statistics.json')\n  with tf.io.gfile.GFile(path, 'r') as f:\n    return json.load(f)\n\n\ndef tfrecord_files(organism, subset):\n  # Sort the values by int(*).\n  return sorted(tf.io.gfile.glob(os.path.join(\n      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n\n\ndef deserialize(serialized_example, metadata):\n  \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n  feature_map = {\n      'sequence': tf.io.FixedLenFeature([], tf.string),\n      'target': tf.io.FixedLenFeature([], tf.string),\n  }\n  example = tf.io.parse_example(serialized_example, feature_map)\n  sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n  sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n  sequence = tf.cast(sequence, tf.float32)\n\n  target = tf.io.decode_raw(example['target'], tf.float16)\n  target = tf.reshape(target,\n                      (metadata['target_length'], metadata['num_targets']))\n  target = tf.cast(target, tf.float32)\n\n  return {'sequence': sequence,\n          'target': target}\n```\n:::\n\n\n## Load dataset\n\n::: {#9e263e21 .cell execution_count=11}\n``` {.python .cell-code}\ndf_targets_human = get_targets('human')\ndf_targets_human.head()\n```\n:::\n\n\n::: {#bca042cb .cell execution_count=12}\n``` {.python .cell-code}\nhuman_dataset = get_dataset('human', 'train').batch(1).repeat()\nmouse_dataset = get_dataset('mouse', 'train').batch(1).repeat()\nhuman_mouse_dataset = tf.data.Dataset.zip((human_dataset, mouse_dataset)).prefetch(2)\n```\n:::\n\n\n::: {#051096a7 .cell execution_count=13}\n``` {.python .cell-code}\nit = iter(mouse_dataset)\nexample = next(it)\n```\n:::\n\n\n::: {#debaf3df .cell execution_count=14}\n``` {.python .cell-code}\n# Example input\nit = iter(human_mouse_dataset)\nexample = next(it)\nfor i in range(len(example)):\n  print(['human', 'mouse'][i])\n  print({k: (v.shape, v.dtype) for k,v in example[i].items()})\n```\n:::\n\n\n## Model training\n\n::: {#533bb840 .cell execution_count=15}\n``` {.python .cell-code}\ndef create_step_function(model, optimizer):\n\n  @tf.function\n  def train_step(batch, head, optimizer_clip_norm_global=0.2):\n    with tf.GradientTape() as tape:\n      outputs = model(batch['sequence'], is_training=True)[head]\n      loss = tf.reduce_mean(\n          tf.keras.losses.poisson(batch['target'], outputs))\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply(gradients, model.trainable_variables)\n\n    return loss\n  return train_step\n```\n:::\n\n\n::: {#38e29a57 .cell execution_count=16}\n``` {.python .cell-code}\nlearning_rate = tf.Variable(0., trainable=False, name='learning_rate')\noptimizer = snt.optimizers.Adam(learning_rate=learning_rate)\nnum_warmup_steps = 5000\ntarget_learning_rate = 0.0005\n\nmodel = enformer.Enformer(channels=1536 // 4,  # Use 4x fewer channels to train faster.\n                          num_heads=8,\n                          num_transformer_layers=11,\n                          pooling_type='max')\n\ntrain_step = create_step_function(model, optimizer)\n```\n:::\n\n\n::: {#4ba1b4dc .cell cellView='code' execution_count=17}\n``` {.python .cell-code}\n# Train the model\nsteps_per_epoch = 20\nnum_epochs = 5\n\ndata_it = iter(human_mouse_dataset)\nglobal_step = 0\nfor epoch_i in range(num_epochs):\n  for i in tqdm(range(steps_per_epoch)):\n    global_step += 1\n\n    if global_step > 1:\n      learning_rate_frac = tf.math.minimum(\n          1.0, global_step / tf.math.maximum(1.0, num_warmup_steps))\n      learning_rate.assign(target_learning_rate * learning_rate_frac)\n\n    batch_human, batch_mouse = next(data_it)\n\n    loss_human = train_step(batch=batch_human, head='human')\n    loss_mouse = train_step(batch=batch_mouse, head='mouse')\n\n  # End of epoch.\n  print('')\n  print('loss_human', loss_human.numpy(),\n        'loss_mouse', loss_mouse.numpy(),\n        'learning_rate', optimizer.learning_rate.numpy()\n        )\n```\n:::\n\n\n## Evaluate\n\n::: {#14d3796f .cell cellView='form' execution_count=18}\n``` {.python .cell-code}\n# @title `PearsonR` and `R2` metrics\n\ndef _reduced_shape(shape, axis):\n  if axis is None:\n    return tf.TensorShape([])\n  return tf.TensorShape([d for i, d in enumerate(shape) if i not in axis])\n\n\nclass CorrelationStats(tf.keras.metrics.Metric):\n  \"\"\"Contains shared code for PearsonR and R2.\"\"\"\n\n  def __init__(self, reduce_axis=None, name='pearsonr'):\n    \"\"\"Pearson correlation coefficient.\n\n    Args:\n      reduce_axis: Specifies over which axis to compute the correlation (say\n        (0, 1). If not specified, it will compute the correlation across the\n        whole tensor.\n      name: Metric name.\n    \"\"\"\n    super(CorrelationStats, self).__init__(name=name)\n    self._reduce_axis = reduce_axis\n    self._shape = None  # Specified in _initialize.\n\n  def _initialize(self, input_shape):\n    # Remaining dimensions after reducing over self._reduce_axis.\n    self._shape = _reduced_shape(input_shape, self._reduce_axis)\n\n    weight_kwargs = dict(shape=self._shape, initializer='zeros')\n    self._count = self.add_weight(name='count', **weight_kwargs)\n    self._product_sum = self.add_weight(name='product_sum', **weight_kwargs)\n    self._true_sum = self.add_weight(name='true_sum', **weight_kwargs)\n    self._true_squared_sum = self.add_weight(name='true_squared_sum',\n                                             **weight_kwargs)\n    self._pred_sum = self.add_weight(name='pred_sum', **weight_kwargs)\n    self._pred_squared_sum = self.add_weight(name='pred_squared_sum',\n                                             **weight_kwargs)\n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n    \"\"\"Update the metric state.\n\n    Args:\n      y_true: Multi-dimensional float tensor [batch, ...] containing the ground\n        truth values.\n      y_pred: float tensor with the same shape as y_true containing predicted\n        values.\n      sample_weight: 1D tensor aligned with y_true batch dimension specifying\n        the weight of individual observations.\n    \"\"\"\n    if self._shape is None:\n      # Explicit initialization check.\n      self._initialize(y_true.shape)\n    y_true.shape.assert_is_compatible_with(y_pred.shape)\n    y_true = tf.cast(y_true, 'float32')\n    y_pred = tf.cast(y_pred, 'float32')\n\n    self._product_sum.assign_add(\n        tf.reduce_sum(y_true * y_pred, axis=self._reduce_axis))\n\n    self._true_sum.assign_add(\n        tf.reduce_sum(y_true, axis=self._reduce_axis))\n\n    self._true_squared_sum.assign_add(\n        tf.reduce_sum(tf.math.square(y_true), axis=self._reduce_axis))\n\n    self._pred_sum.assign_add(\n        tf.reduce_sum(y_pred, axis=self._reduce_axis))\n\n    self._pred_squared_sum.assign_add(\n        tf.reduce_sum(tf.math.square(y_pred), axis=self._reduce_axis))\n\n    self._count.assign_add(\n        tf.reduce_sum(tf.ones_like(y_true), axis=self._reduce_axis))\n\n  def result(self):\n    raise NotImplementedError('Must be implemented in subclasses.')\n\n  def reset_states(self):\n    if self._shape is not None:\n      tf.keras.backend.batch_set_value([(v, np.zeros(self._shape))\n                                        for v in self.variables])\n\n\nclass PearsonR(CorrelationStats):\n  \"\"\"Pearson correlation coefficient.\n\n  Computed as:\n  ((x - x_avg) * (y - y_avg) / sqrt(Var[x] * Var[y])\n  \"\"\"\n\n  def __init__(self, reduce_axis=(0,), name='pearsonr'):\n    \"\"\"Pearson correlation coefficient.\n\n    Args:\n      reduce_axis: Specifies over which axis to compute the correlation.\n      name: Metric name.\n    \"\"\"\n    super(PearsonR, self).__init__(reduce_axis=reduce_axis,\n                                   name=name)\n\n  def result(self):\n    true_mean = self._true_sum / self._count\n    pred_mean = self._pred_sum / self._count\n\n    covariance = (self._product_sum\n                  - true_mean * self._pred_sum\n                  - pred_mean * self._true_sum\n                  + self._count * true_mean * pred_mean)\n\n    true_var = self._true_squared_sum - self._count * tf.math.square(true_mean)\n    pred_var = self._pred_squared_sum - self._count * tf.math.square(pred_mean)\n    tp_var = tf.math.sqrt(true_var) * tf.math.sqrt(pred_var)\n    correlation = covariance / tp_var\n\n    return correlation\n\n\nclass R2(CorrelationStats):\n  \"\"\"R-squared  (fraction of explained variance).\"\"\"\n\n  def __init__(self, reduce_axis=None, name='R2'):\n    \"\"\"R-squared metric.\n\n    Args:\n      reduce_axis: Specifies over which axis to compute the correlation.\n      name: Metric name.\n    \"\"\"\n    super(R2, self).__init__(reduce_axis=reduce_axis,\n                             name=name)\n\n  def result(self):\n    true_mean = self._true_sum / self._count\n    total = self._true_squared_sum - self._count * tf.math.square(true_mean)\n    residuals = (self._pred_squared_sum - 2 * self._product_sum\n                 + self._true_squared_sum)\n\n    return tf.ones_like(residuals) - residuals / total\n\n\nclass MetricDict:\n  def __init__(self, metrics):\n    self._metrics = metrics\n\n  def update_state(self, y_true, y_pred):\n    for k, metric in self._metrics.items():\n      metric.update_state(y_true, y_pred)\n\n  def result(self):\n    return {k: metric.result() for k, metric in self._metrics.items()}\n```\n:::\n\n\n::: {#629797f5 .cell execution_count=19}\n``` {.python .cell-code}\ndef evaluate_model(model, dataset, head, max_steps=None):\n  metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n  @tf.function\n  def predict(x):\n    return model(x, is_training=False)[head]\n\n  for i, batch in tqdm(enumerate(dataset)):\n    if max_steps is not None and i > max_steps:\n      break\n    metric.update_state(batch['target'], predict(batch['sequence']))\n\n  return metric.result()\n```\n:::\n\n\n::: {#9bba68bb .cell execution_count=20}\n``` {.python .cell-code}\nmetrics_human = evaluate_model(model,\n                               dataset=get_dataset('human', 'valid').batch(1).prefetch(2),\n                               head='human',\n                               max_steps=100)\nprint('')\nprint({k: v.numpy().mean() for k, v in metrics_human.items()})\n```\n:::\n\n\n::: {#1ac37f75 .cell execution_count=21}\n``` {.python .cell-code}\nmetrics_mouse = evaluate_model(model,\n                               dataset=get_dataset('mouse', 'valid').batch(1).prefetch(2),\n                               head='mouse',\n                               max_steps=100)\nprint('')\nprint({k: v.numpy().mean() for k, v in metrics_mouse.items()})\n```\n:::\n\n\n# Restore Checkpoint\n\nNote: For the TF-Hub Enformer model, the required input sequence length is 393,216 which actually gets cropped within the model to 196,608. The open source module does not internally crop the sequence. Therefore, the code below crops the central `196,608 bp` of the longer sequence to reproduce the output of the TF hub from the reloaded checkpoint.\n\n::: {#106bdc4a .cell execution_count=22}\n``` {.python .cell-code}\nnp.random.seed(42)\nEXTENDED_SEQ_LENGTH = 393_216\nSEQ_LENGTH = 196_608\ninputs = np.array(np.random.random((1, EXTENDED_SEQ_LENGTH, 4)), dtype=np.float32)\ninputs_cropped = enformer.TargetLengthCrop1D(SEQ_LENGTH)(inputs)\n```\n:::\n\n\n::: {#75347880 .cell execution_count=23}\n``` {.python .cell-code}\ncheckpoint_gs_path = 'gs://dm-enformer/models/enformer/sonnet_weights/*'\ncheckpoint_path = '/tmp/enformer_checkpoint'\n```\n:::\n\n\n::: {#65fad4d9 .cell execution_count=24}\n``` {.python .cell-code}\n!mkdir /tmp/enformer_checkpoint\n```\n:::\n\n\n::: {#9c2ca748 .cell execution_count=25}\n``` {.python .cell-code}\n# Copy checkpoints from GCS to temporary directory.\n# This will take a while as the checkpoint is ~ 1GB.\nfor file_path in tf.io.gfile.glob(checkpoint_gs_path):\n  print(file_path)\n  file_name = os.path.basename(file_path)\n  tf.io.gfile.copy(file_path, f'{checkpoint_path}/{file_name}', overwrite=True)\n```\n:::\n\n\n::: {#acf95bf3 .cell execution_count=26}\n``` {.python .cell-code}\n!ls -lh /tmp/enformer_checkpoint\n```\n:::\n\n\n::: {#058621ed .cell execution_count=27}\n``` {.python .cell-code}\nenformer_model = enformer.Enformer()\n```\n:::\n\n\n::: {#d71f26b5 .cell execution_count=28}\n``` {.python .cell-code}\ncheckpoint = tf.train.Checkpoint(module=enformer_model)\n```\n:::\n\n\n::: {#527b4686 .cell execution_count=29}\n``` {.python .cell-code}\nlatest = tf.train.latest_checkpoint(checkpoint_path)\nprint(latest)\nstatus = checkpoint.restore(latest)\n```\n:::\n\n\n::: {#573d116c .cell execution_count=30}\n``` {.python .cell-code}\n# Using `is_training=False` to match TF-hub predict_on_batch function.\nrestored_predictions = enformer_model(inputs_cropped, is_training=False)\n```\n:::\n\n\n::: {#6be22835 .cell execution_count=31}\n``` {.python .cell-code}\nimport tensorflow_hub as hub\nenformer_tf_hub_model = hub.load(\"https://tfhub.dev/deepmind/enformer/1\").model\n```\n:::\n\n\n::: {#0e3e372c .cell execution_count=32}\n``` {.python .cell-code}\nhub_predictions = enformer_tf_hub_model.predict_on_batch(inputs)\n```\n:::\n\n\n::: {#65848e9a .cell execution_count=33}\n``` {.python .cell-code}\nnp.allclose(hub_predictions['human'], restored_predictions['human'], atol=1e-5)\n```\n:::\n\n\n::: {#e961195f .cell execution_count=34}\n``` {.python .cell-code}\n# Can run with 'is_training=True' but note that this will\n# change the predictions as the batch statistics will be updated\n# and the outputs will likley not match the TF-hub model.\n# enformer(inputs_cropped, is_training=True)\n```\n:::\n\n\n",
    "supporting": [
      "enformer_training_files"
    ],
    "filters": [],
    "includes": {}
  }
}