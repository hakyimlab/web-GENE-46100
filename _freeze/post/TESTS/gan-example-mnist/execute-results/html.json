{
  "hash": "543cb0c49b80065c2f80ed8f2b17f39d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: gan example mnist \ndate: 2020-01-02\neval: true\nfreeze: true\ncategories:\n  - notebook\njupyter: \n  kernelspec:\n    name: \"conda-env-gene46100-py\"\n    language: \"python\"\n    display_name: \"gene46100\"\n---\n\n::: {#abb44249 .cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nfrom torch import nn, optim\nimport torchvision.transforms as transforms\nimport torchvision\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {#3ba2a413 .cell execution_count=2}\n``` {.python .cell-code}\n# Custom Reshape layer\nclass Reshape(nn.Module):\n    def __init__(self, *args):\n        super(Reshape, self).__init__()\n        self.shape = args\n\n    def forward(self, x):\n        return x.view(x.shape[0], *self.shape)\n\n# Define Generator network with convolutional layers\nclass Generator(nn.Module):\n    def __init__(self, z_dim=100):\n        super(Generator, self).__init__()\n        self.gen = nn.Sequential(\n            # First layer\n            nn.Linear(z_dim, 7*7*256),\n            nn.BatchNorm1d(7*7*256),\n            nn.ReLU(True),\n            \n            # Reshape to start convolutions\n            Reshape(256, 7, 7),\n            \n            # Convolution layers\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        return self.gen(x)\n\n# Define Discriminator network with convolutional layers\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # First conv layer\n            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.3),\n            \n            # Second conv layer\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.3),\n            \n            # Flatten and dense layers\n            nn.Flatten(),\n            nn.Linear(128 * 7 * 7, 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            \n            nn.Linear(1024, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.disc(x)\n\n# Hyperparameters\nz_dim = 100\nlr = 2e-4      # Slightly adjusted learning rate\nbeta1 = 0.5    # Beta1 for Adam optimizer\nbatch_size = 128  # Increased batch size\nepochs = 20    # Increased epochs\n\n# Set up device\ndevice = torch.device(\"mps\")\n\n# Data loading with normalization [-1, 1]\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndataset = torchvision.datasets.MNIST(root='data/', train=True, transform=transform, download=True)\nloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Initialize models and move to MPS\ngenerator = Generator(z_dim).to(device)\ndiscriminator = Discriminator().to(device)\n\n# Optimizers with beta1\noptimG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\noptimD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n\n# Loss function\ncriterion = nn.BCELoss()\n\n# Training loop with improved stability\nfor epoch in range(epochs):\n    for batch_idx, (real_images, _) in enumerate(loader):\n        batch_size_current = real_images.shape[0]\n        \n        # Move data to MPS\n        real_images = real_images.to(device)\n        \n        # Train Discriminator\n        discriminator.zero_grad()\n        label_real = torch.ones(batch_size_current, 1).to(device)\n        label_fake = torch.zeros(batch_size_current, 1).to(device)\n        \n        output_real = discriminator(real_images)\n        d_loss_real = criterion(output_real, label_real)\n        \n        noise = torch.randn(batch_size_current, z_dim).to(device)\n        fake_images = generator(noise)\n        output_fake = discriminator(fake_images.detach())\n        d_loss_fake = criterion(output_fake, label_fake)\n        \n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n        optimD.step()\n        \n        # Train Generator\n        generator.zero_grad()\n        output_fake = discriminator(fake_images)\n        g_loss = criterion(output_fake, label_real)\n        \n        g_loss.backward()\n        optimG.step()\n        \n        if batch_idx % 100 == 0:\n            print(f'Epoch [{epoch}/{epochs}] Batch [{batch_idx}/{len(loader)}] '\n                  f'd_loss: {d_loss.item():.4f} g_loss: {g_loss.item():.4f}')\n\n    # Generate and save sample images after each epoch\n    if (epoch + 1) % 5 == 0:\n        with torch.no_grad():\n            test_noise = torch.randn(5, z_dim).to(device)\n            generated_images = generator(test_noise)\n            \n            plt.figure(figsize=(10, 2))\n            for i in range(5):\n                plt.subplot(1, 5, i + 1)\n                # Move tensor back to CPU for plotting\n                plt.imshow(generated_images[i].cpu().squeeze().numpy(), cmap='gray')\n                plt.axis('off')\n            plt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [0/20] Batch [0/469] d_loss: 1.4239 g_loss: 0.7677\nEpoch [0/20] Batch [100/469] d_loss: 1.3850 g_loss: 0.7145\nEpoch [0/20] Batch [200/469] d_loss: 1.2254 g_loss: 0.8191\nEpoch [0/20] Batch [300/469] d_loss: 0.8246 g_loss: 1.1075\nEpoch [0/20] Batch [400/469] d_loss: 0.7940 g_loss: 1.4329\nEpoch [1/20] Batch [0/469] d_loss: 0.6574 g_loss: 1.4599\nEpoch [1/20] Batch [100/469] d_loss: 0.6153 g_loss: 1.8150\nEpoch [1/20] Batch [200/469] d_loss: 1.1240 g_loss: 1.0195\nEpoch [1/20] Batch [300/469] d_loss: 1.4135 g_loss: 0.8613\nEpoch [1/20] Batch [400/469] d_loss: 1.4124 g_loss: 0.9036\nEpoch [2/20] Batch [0/469] d_loss: 1.3630 g_loss: 0.8527\nEpoch [2/20] Batch [100/469] d_loss: 1.2163 g_loss: 0.9640\nEpoch [2/20] Batch [200/469] d_loss: 1.3488 g_loss: 0.7491\nEpoch [2/20] Batch [300/469] d_loss: 1.2910 g_loss: 0.8418\nEpoch [2/20] Batch [400/469] d_loss: 1.2164 g_loss: 0.8686\nEpoch [3/20] Batch [0/469] d_loss: 1.2882 g_loss: 0.8355\nEpoch [3/20] Batch [100/469] d_loss: 1.2517 g_loss: 0.9931\nEpoch [3/20] Batch [200/469] d_loss: 1.2008 g_loss: 0.9636\nEpoch [3/20] Batch [300/469] d_loss: 1.2776 g_loss: 1.1015\nEpoch [3/20] Batch [400/469] d_loss: 1.2742 g_loss: 0.9338\nEpoch [4/20] Batch [0/469] d_loss: 1.2320 g_loss: 0.8290\nEpoch [4/20] Batch [100/469] d_loss: 1.1950 g_loss: 0.8534\nEpoch [4/20] Batch [200/469] d_loss: 1.2451 g_loss: 0.8164\nEpoch [4/20] Batch [300/469] d_loss: 1.1428 g_loss: 0.8949\nEpoch [4/20] Batch [400/469] d_loss: 1.2496 g_loss: 0.9143\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [5/20] Batch [0/469] d_loss: 1.3455 g_loss: 0.8387\nEpoch [5/20] Batch [100/469] d_loss: 1.2845 g_loss: 0.8872\nEpoch [5/20] Batch [200/469] d_loss: 1.2622 g_loss: 0.8158\nEpoch [5/20] Batch [300/469] d_loss: 1.2124 g_loss: 0.8662\nEpoch [5/20] Batch [400/469] d_loss: 1.2249 g_loss: 0.9399\nEpoch [6/20] Batch [0/469] d_loss: 1.2702 g_loss: 0.9003\nEpoch [6/20] Batch [100/469] d_loss: 1.2332 g_loss: 0.9916\nEpoch [6/20] Batch [200/469] d_loss: 1.2569 g_loss: 0.9638\nEpoch [6/20] Batch [300/469] d_loss: 1.1346 g_loss: 0.8724\nEpoch [6/20] Batch [400/469] d_loss: 1.2020 g_loss: 0.8598\nEpoch [7/20] Batch [0/469] d_loss: 1.3056 g_loss: 0.9416\nEpoch [7/20] Batch [100/469] d_loss: 1.2384 g_loss: 0.9818\nEpoch [7/20] Batch [200/469] d_loss: 1.2414 g_loss: 1.0582\nEpoch [7/20] Batch [300/469] d_loss: 1.2354 g_loss: 0.9607\nEpoch [7/20] Batch [400/469] d_loss: 1.1738 g_loss: 0.8974\nEpoch [8/20] Batch [0/469] d_loss: 1.1154 g_loss: 0.8861\nEpoch [8/20] Batch [100/469] d_loss: 1.2155 g_loss: 0.8860\nEpoch [8/20] Batch [200/469] d_loss: 1.2716 g_loss: 0.8284\nEpoch [8/20] Batch [300/469] d_loss: 1.2200 g_loss: 0.8618\nEpoch [8/20] Batch [400/469] d_loss: 1.2214 g_loss: 0.9329\nEpoch [9/20] Batch [0/469] d_loss: 1.1621 g_loss: 0.9471\nEpoch [9/20] Batch [100/469] d_loss: 1.2423 g_loss: 1.0075\nEpoch [9/20] Batch [200/469] d_loss: 1.1191 g_loss: 1.0043\nEpoch [9/20] Batch [300/469] d_loss: 1.1531 g_loss: 0.9500\nEpoch [9/20] Batch [400/469] d_loss: 1.2360 g_loss: 0.9542\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [10/20] Batch [0/469] d_loss: 1.1941 g_loss: 0.8702\nEpoch [10/20] Batch [100/469] d_loss: 1.2769 g_loss: 0.9748\nEpoch [10/20] Batch [200/469] d_loss: 1.2864 g_loss: 0.9974\nEpoch [10/20] Batch [300/469] d_loss: 1.2404 g_loss: 0.7765\nEpoch [10/20] Batch [400/469] d_loss: 1.1253 g_loss: 0.8605\nEpoch [11/20] Batch [0/469] d_loss: 1.3187 g_loss: 0.9972\nEpoch [11/20] Batch [100/469] d_loss: 1.1936 g_loss: 1.0513\nEpoch [11/20] Batch [200/469] d_loss: 1.1790 g_loss: 0.9714\nEpoch [11/20] Batch [300/469] d_loss: 1.2461 g_loss: 1.0150\nEpoch [11/20] Batch [400/469] d_loss: 1.3452 g_loss: 1.0451\nEpoch [12/20] Batch [0/469] d_loss: 1.2775 g_loss: 0.7984\nEpoch [12/20] Batch [100/469] d_loss: 1.2940 g_loss: 1.1000\nEpoch [12/20] Batch [200/469] d_loss: 1.1843 g_loss: 1.0152\nEpoch [12/20] Batch [300/469] d_loss: 1.2907 g_loss: 0.9341\nEpoch [12/20] Batch [400/469] d_loss: 1.2473 g_loss: 0.9298\nEpoch [13/20] Batch [0/469] d_loss: 1.1615 g_loss: 1.1194\nEpoch [13/20] Batch [100/469] d_loss: 1.2015 g_loss: 0.8435\nEpoch [13/20] Batch [200/469] d_loss: 1.2681 g_loss: 0.9003\nEpoch [13/20] Batch [300/469] d_loss: 1.2993 g_loss: 0.9530\nEpoch [13/20] Batch [400/469] d_loss: 1.1187 g_loss: 0.9645\nEpoch [14/20] Batch [0/469] d_loss: 1.2024 g_loss: 0.9993\nEpoch [14/20] Batch [100/469] d_loss: 1.2476 g_loss: 0.9358\nEpoch [14/20] Batch [200/469] d_loss: 1.1476 g_loss: 1.0313\nEpoch [14/20] Batch [300/469] d_loss: 1.1285 g_loss: 0.9711\nEpoch [14/20] Batch [400/469] d_loss: 1.2464 g_loss: 0.9414\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [15/20] Batch [0/469] d_loss: 1.1634 g_loss: 1.0355\nEpoch [15/20] Batch [100/469] d_loss: 1.1517 g_loss: 0.9213\nEpoch [15/20] Batch [200/469] d_loss: 1.3466 g_loss: 0.9449\nEpoch [15/20] Batch [300/469] d_loss: 1.2163 g_loss: 0.8658\nEpoch [15/20] Batch [400/469] d_loss: 1.2534 g_loss: 1.0694\nEpoch [16/20] Batch [0/469] d_loss: 1.1684 g_loss: 0.9559\nEpoch [16/20] Batch [100/469] d_loss: 1.1436 g_loss: 1.0252\nEpoch [16/20] Batch [200/469] d_loss: 1.2818 g_loss: 0.8296\nEpoch [16/20] Batch [300/469] d_loss: 1.2035 g_loss: 0.9181\nEpoch [16/20] Batch [400/469] d_loss: 1.3543 g_loss: 0.9777\nEpoch [17/20] Batch [0/469] d_loss: 1.1087 g_loss: 1.0090\nEpoch [17/20] Batch [100/469] d_loss: 1.1419 g_loss: 1.0329\nEpoch [17/20] Batch [200/469] d_loss: 1.1968 g_loss: 1.0202\nEpoch [17/20] Batch [300/469] d_loss: 1.3013 g_loss: 1.0606\nEpoch [17/20] Batch [400/469] d_loss: 1.3185 g_loss: 1.0476\nEpoch [18/20] Batch [0/469] d_loss: 1.1677 g_loss: 0.9461\nEpoch [18/20] Batch [100/469] d_loss: 1.1302 g_loss: 0.9498\nEpoch [18/20] Batch [200/469] d_loss: 1.2141 g_loss: 1.0275\nEpoch [18/20] Batch [300/469] d_loss: 1.2473 g_loss: 0.9661\nEpoch [18/20] Batch [400/469] d_loss: 1.2429 g_loss: 1.0230\nEpoch [19/20] Batch [0/469] d_loss: 1.1401 g_loss: 0.9990\nEpoch [19/20] Batch [100/469] d_loss: 1.1564 g_loss: 0.8947\nEpoch [19/20] Batch [200/469] d_loss: 1.1397 g_loss: 1.0643\nEpoch [19/20] Batch [300/469] d_loss: 1.1948 g_loss: 1.1179\nEpoch [19/20] Batch [400/469] d_loss: 1.2008 g_loss: 0.9639\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-8.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "gan-example-mnist_files"
    ],
    "filters": [],
    "includes": {}
  }
}