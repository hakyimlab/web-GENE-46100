{
  "hash": "543cb0c49b80065c2f80ed8f2b17f39d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: gan example mnist \ndate: 2020-01-02\neval: true\nfreeze: true\ncategories:\n  - notebook\njupyter: \n  kernelspec:\n    name: \"conda-env-gene46100-py\"\n    language: \"python\"\n    display_name: \"gene46100\"\n---\n\n::: {#d264ea47 .cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nfrom torch import nn, optim\nimport torchvision.transforms as transforms\nimport torchvision\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {#cf9956d5 .cell execution_count=2}\n``` {.python .cell-code}\n# Custom Reshape layer\nclass Reshape(nn.Module):\n    def __init__(self, *args):\n        super(Reshape, self).__init__()\n        self.shape = args\n\n    def forward(self, x):\n        return x.view(x.shape[0], *self.shape)\n\n# Define Generator network with convolutional layers\nclass Generator(nn.Module):\n    def __init__(self, z_dim=100):\n        super(Generator, self).__init__()\n        self.gen = nn.Sequential(\n            # First layer\n            nn.Linear(z_dim, 7*7*256),\n            nn.BatchNorm1d(7*7*256),\n            nn.ReLU(True),\n            \n            # Reshape to start convolutions\n            Reshape(256, 7, 7),\n            \n            # Convolution layers\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        return self.gen(x)\n\n# Define Discriminator network with convolutional layers\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # First conv layer\n            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.3),\n            \n            # Second conv layer\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.3),\n            \n            # Flatten and dense layers\n            nn.Flatten(),\n            nn.Linear(128 * 7 * 7, 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            \n            nn.Linear(1024, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.disc(x)\n\n# Hyperparameters\nz_dim = 100\nlr = 2e-4      # Slightly adjusted learning rate\nbeta1 = 0.5    # Beta1 for Adam optimizer\nbatch_size = 128  # Increased batch size\nepochs = 20    # Increased epochs\n\n# Set up device\ndevice = torch.device(\"mps\")\n\n# Data loading with normalization [-1, 1]\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndataset = torchvision.datasets.MNIST(root='data/', train=True, transform=transform, download=True)\nloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Initialize models and move to MPS\ngenerator = Generator(z_dim).to(device)\ndiscriminator = Discriminator().to(device)\n\n# Optimizers with beta1\noptimG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\noptimD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n\n# Loss function\ncriterion = nn.BCELoss()\n\n# Training loop with improved stability\nfor epoch in range(epochs):\n    for batch_idx, (real_images, _) in enumerate(loader):\n        batch_size_current = real_images.shape[0]\n        \n        # Move data to MPS\n        real_images = real_images.to(device)\n        \n        # Train Discriminator\n        discriminator.zero_grad()\n        label_real = torch.ones(batch_size_current, 1).to(device)\n        label_fake = torch.zeros(batch_size_current, 1).to(device)\n        \n        output_real = discriminator(real_images)\n        d_loss_real = criterion(output_real, label_real)\n        \n        noise = torch.randn(batch_size_current, z_dim).to(device)\n        fake_images = generator(noise)\n        output_fake = discriminator(fake_images.detach())\n        d_loss_fake = criterion(output_fake, label_fake)\n        \n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n        optimD.step()\n        \n        # Train Generator\n        generator.zero_grad()\n        output_fake = discriminator(fake_images)\n        g_loss = criterion(output_fake, label_real)\n        \n        g_loss.backward()\n        optimG.step()\n        \n        if batch_idx % 100 == 0:\n            print(f'Epoch [{epoch}/{epochs}] Batch [{batch_idx}/{len(loader)}] '\n                  f'd_loss: {d_loss.item():.4f} g_loss: {g_loss.item():.4f}')\n\n    # Generate and save sample images after each epoch\n    if (epoch + 1) % 5 == 0:\n        with torch.no_grad():\n            test_noise = torch.randn(5, z_dim).to(device)\n            generated_images = generator(test_noise)\n            \n            plt.figure(figsize=(10, 2))\n            for i in range(5):\n                plt.subplot(1, 5, i + 1)\n                # Move tensor back to CPU for plotting\n                plt.imshow(generated_images[i].cpu().squeeze().numpy(), cmap='gray')\n                plt.axis('off')\n            plt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [0/20] Batch [0/469] d_loss: 1.4587 g_loss: 0.7364\nEpoch [0/20] Batch [100/469] d_loss: 1.3710 g_loss: 0.7146\nEpoch [0/20] Batch [200/469] d_loss: 1.1290 g_loss: 0.8700\nEpoch [0/20] Batch [300/469] d_loss: 0.9860 g_loss: 1.1322\nEpoch [0/20] Batch [400/469] d_loss: 0.4725 g_loss: 1.9018\nEpoch [1/20] Batch [0/469] d_loss: 0.5324 g_loss: 1.8864\nEpoch [1/20] Batch [100/469] d_loss: 0.3427 g_loss: 2.4291\nEpoch [1/20] Batch [200/469] d_loss: 0.2379 g_loss: 2.6575\nEpoch [1/20] Batch [300/469] d_loss: 0.2059 g_loss: 3.3945\nEpoch [1/20] Batch [400/469] d_loss: 0.1537 g_loss: 3.2048\nEpoch [2/20] Batch [0/469] d_loss: 0.3866 g_loss: 2.3630\nEpoch [2/20] Batch [100/469] d_loss: 0.2228 g_loss: 2.8267\nEpoch [2/20] Batch [200/469] d_loss: 0.1287 g_loss: 3.4258\nEpoch [2/20] Batch [300/469] d_loss: 0.1049 g_loss: 3.9926\nEpoch [2/20] Batch [400/469] d_loss: 0.2627 g_loss: 3.3500\nEpoch [3/20] Batch [0/469] d_loss: 0.1071 g_loss: 3.8937\nEpoch [3/20] Batch [100/469] d_loss: 0.1239 g_loss: 3.4904\nEpoch [3/20] Batch [200/469] d_loss: 0.0526 g_loss: 4.2760\nEpoch [3/20] Batch [300/469] d_loss: 0.1703 g_loss: 3.7801\nEpoch [3/20] Batch [400/469] d_loss: 1.5493 g_loss: 0.7978\nEpoch [4/20] Batch [0/469] d_loss: 1.4743 g_loss: 0.8553\nEpoch [4/20] Batch [100/469] d_loss: 1.5439 g_loss: 0.8430\nEpoch [4/20] Batch [200/469] d_loss: 1.5271 g_loss: 0.8607\nEpoch [4/20] Batch [300/469] d_loss: 1.3586 g_loss: 0.7892\nEpoch [4/20] Batch [400/469] d_loss: 1.3883 g_loss: 0.8830\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [5/20] Batch [0/469] d_loss: 1.5093 g_loss: 0.9424\nEpoch [5/20] Batch [100/469] d_loss: 1.4322 g_loss: 1.0056\nEpoch [5/20] Batch [200/469] d_loss: 1.3403 g_loss: 0.9821\nEpoch [5/20] Batch [300/469] d_loss: 1.3601 g_loss: 0.8536\nEpoch [5/20] Batch [400/469] d_loss: 1.3104 g_loss: 0.7968\nEpoch [6/20] Batch [0/469] d_loss: 1.1751 g_loss: 0.9554\nEpoch [6/20] Batch [100/469] d_loss: 1.3790 g_loss: 0.9607\nEpoch [6/20] Batch [200/469] d_loss: 1.2350 g_loss: 0.7746\nEpoch [6/20] Batch [300/469] d_loss: 1.2191 g_loss: 0.8583\nEpoch [6/20] Batch [400/469] d_loss: 1.2714 g_loss: 0.9669\nEpoch [7/20] Batch [0/469] d_loss: 1.3526 g_loss: 0.8643\nEpoch [7/20] Batch [100/469] d_loss: 1.3798 g_loss: 0.9228\nEpoch [7/20] Batch [200/469] d_loss: 1.3123 g_loss: 0.8387\nEpoch [7/20] Batch [300/469] d_loss: 1.2502 g_loss: 0.9403\nEpoch [7/20] Batch [400/469] d_loss: 1.3042 g_loss: 0.9029\nEpoch [8/20] Batch [0/469] d_loss: 1.2249 g_loss: 0.8839\nEpoch [8/20] Batch [100/469] d_loss: 1.2266 g_loss: 0.8993\nEpoch [8/20] Batch [200/469] d_loss: 1.2863 g_loss: 0.8482\nEpoch [8/20] Batch [300/469] d_loss: 1.2024 g_loss: 0.9778\nEpoch [8/20] Batch [400/469] d_loss: 1.1278 g_loss: 0.8528\nEpoch [9/20] Batch [0/469] d_loss: 1.1930 g_loss: 0.9338\nEpoch [9/20] Batch [100/469] d_loss: 1.3779 g_loss: 0.8452\nEpoch [9/20] Batch [200/469] d_loss: 1.2220 g_loss: 1.0130\nEpoch [9/20] Batch [300/469] d_loss: 1.2013 g_loss: 0.9121\nEpoch [9/20] Batch [400/469] d_loss: 1.2612 g_loss: 1.0147\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [10/20] Batch [0/469] d_loss: 1.1912 g_loss: 0.9411\nEpoch [10/20] Batch [100/469] d_loss: 1.1474 g_loss: 0.9353\nEpoch [10/20] Batch [200/469] d_loss: 1.2389 g_loss: 0.8523\nEpoch [10/20] Batch [300/469] d_loss: 1.1961 g_loss: 0.7835\nEpoch [10/20] Batch [400/469] d_loss: 1.1892 g_loss: 0.9633\nEpoch [11/20] Batch [0/469] d_loss: 1.1884 g_loss: 0.8253\nEpoch [11/20] Batch [100/469] d_loss: 1.2928 g_loss: 0.9628\nEpoch [11/20] Batch [200/469] d_loss: 1.1756 g_loss: 0.9246\nEpoch [11/20] Batch [300/469] d_loss: 1.2237 g_loss: 0.9206\nEpoch [11/20] Batch [400/469] d_loss: 1.1077 g_loss: 0.9726\nEpoch [12/20] Batch [0/469] d_loss: 1.2371 g_loss: 1.0076\nEpoch [12/20] Batch [100/469] d_loss: 1.2275 g_loss: 0.9172\nEpoch [12/20] Batch [200/469] d_loss: 1.2303 g_loss: 0.9334\nEpoch [12/20] Batch [300/469] d_loss: 1.1339 g_loss: 0.9581\nEpoch [12/20] Batch [400/469] d_loss: 1.2166 g_loss: 1.0264\nEpoch [13/20] Batch [0/469] d_loss: 1.2645 g_loss: 0.8292\nEpoch [13/20] Batch [100/469] d_loss: 1.2263 g_loss: 0.9388\nEpoch [13/20] Batch [200/469] d_loss: 1.2474 g_loss: 0.9823\nEpoch [13/20] Batch [300/469] d_loss: 1.2536 g_loss: 0.9741\nEpoch [13/20] Batch [400/469] d_loss: 1.2097 g_loss: 0.9343\nEpoch [14/20] Batch [0/469] d_loss: 1.2619 g_loss: 0.9633\nEpoch [14/20] Batch [100/469] d_loss: 1.3268 g_loss: 0.9094\nEpoch [14/20] Batch [200/469] d_loss: 1.2769 g_loss: 0.9404\nEpoch [14/20] Batch [300/469] d_loss: 1.1858 g_loss: 0.9609\nEpoch [14/20] Batch [400/469] d_loss: 1.2346 g_loss: 1.0119\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [15/20] Batch [0/469] d_loss: 1.1835 g_loss: 0.9720\nEpoch [15/20] Batch [100/469] d_loss: 1.2663 g_loss: 0.9126\nEpoch [15/20] Batch [200/469] d_loss: 1.2762 g_loss: 0.8213\nEpoch [15/20] Batch [300/469] d_loss: 1.1572 g_loss: 0.8374\nEpoch [15/20] Batch [400/469] d_loss: 1.0717 g_loss: 0.9020\nEpoch [16/20] Batch [0/469] d_loss: 1.2640 g_loss: 0.9940\nEpoch [16/20] Batch [100/469] d_loss: 1.2792 g_loss: 1.0197\nEpoch [16/20] Batch [200/469] d_loss: 1.3113 g_loss: 0.9563\nEpoch [16/20] Batch [300/469] d_loss: 1.2178 g_loss: 0.9577\nEpoch [16/20] Batch [400/469] d_loss: 1.2632 g_loss: 0.9852\nEpoch [17/20] Batch [0/469] d_loss: 1.2279 g_loss: 0.9235\nEpoch [17/20] Batch [100/469] d_loss: 1.3499 g_loss: 0.9113\nEpoch [17/20] Batch [200/469] d_loss: 1.1605 g_loss: 0.9119\nEpoch [17/20] Batch [300/469] d_loss: 1.2327 g_loss: 0.8470\nEpoch [17/20] Batch [400/469] d_loss: 1.1778 g_loss: 0.9232\nEpoch [18/20] Batch [0/469] d_loss: 1.4804 g_loss: 0.8219\nEpoch [18/20] Batch [100/469] d_loss: 1.3487 g_loss: 0.8752\nEpoch [18/20] Batch [200/469] d_loss: 1.2347 g_loss: 0.8730\nEpoch [18/20] Batch [300/469] d_loss: 1.2076 g_loss: 0.9315\nEpoch [18/20] Batch [400/469] d_loss: 1.2874 g_loss: 0.8813\nEpoch [19/20] Batch [0/469] d_loss: 1.2302 g_loss: 1.0094\nEpoch [19/20] Batch [100/469] d_loss: 1.2215 g_loss: 0.8352\nEpoch [19/20] Batch [200/469] d_loss: 1.2204 g_loss: 0.9764\nEpoch [19/20] Batch [300/469] d_loss: 1.3497 g_loss: 0.8585\nEpoch [19/20] Batch [400/469] d_loss: 1.2276 g_loss: 0.9919\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](gan-example-mnist_files/figure-html/cell-3-output-8.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "gan-example-mnist_files"
    ],
    "filters": [],
    "includes": {}
  }
}