{
  "hash": "fc027c65ad186473250554ce63908443",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: scanpy tutorial - qmd\ndate: '2025-05-12'\nauthor: scanpy authors\neval: true\ncategories:\n  - notebook\nfreeze: true\njupyter: \n  kernelspec:\n    name: \"conda-env-scanpy-tutorial-py\"\n    language: \"python\"\n    display_name: \"scanpy-tutorial\"\n---\n\n\nThis notebook is not compatible with this python 3.12. Some issues with pickle data and celltypist.\n\n\n```{{bash}}\nconda create --name scanpy-tutorial python=3.9\nconda activate scanpy-tutorial\nconda install nb_conda_kernels jupyter_server\npip install nbclient nbformat\n```\n\n::: {#98a58fa6 .cell execution_count=1}\n``` {.python .cell-code}\n# set first time to False to avoid multiple downloads\nfirst_time = False\nprint(first_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFalse\n```\n:::\n:::\n\n\n# Preprocessing and clustering\n\n::: {#ad50de2b .cell execution_count=2}\n``` {.python .cell-code}\ntry:\n    import anndata as ad\nexcept ImportError:\n    %pip install anndata\n    import anndata as ad\ntry:\n    import pooch\nexcept ImportError:\n    %pip install pooch\n    import pooch\ntry:\n    import scanpy as sc\nexcept ImportError:\n    %pip install scanpy\n    import scanpy as sc\n\ntry:\n    import scrublet\nexcept ImportError:\n    %pip install scrublet\n    import scrublet\ntry:\n    import skimage \nexcept ImportError:\n    %pip install scikit-image\n    import skimage\ntry:\n    import igraph\nexcept ImportError:\n    %pip install igraph\n    import igraph\n```\n:::\n\n\n::: {#7eaca72f .cell execution_count=3}\n``` {.python .cell-code}\nsc.settings.set_figure_params(dpi=50, facecolor=\"white\")\n```\n:::\n\n\nThe data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors and was part of [openproblem's NeurIPS 2021 benchmarking dataset](https://openproblems.bio/competitions/neurips_2021/) {cite}`luecken2021`. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit. \n\n\nWe are reading in the count matrix into an [AnnData](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html) object, which holds many slots for annotations and different representations of the data.\n\n::: {#825ef6d2 .cell execution_count=4}\n``` {.python .cell-code}\nEXAMPLE_DATA = pooch.create(\n    path=pooch.os_cache(\"scverse_tutorials\"),\n    base_url=\"doi:10.6084/m9.figshare.22716739.v1/\",\n)\nEXAMPLE_DATA.load_registry_from_doi()\n```\n:::\n\n\n::: {#ca603a0b .cell execution_count=5}\n``` {.python .cell-code}\nsamples = {\n    \"s1d1\": \"s1d1_filtered_feature_bc_matrix.h5\",\n    \"s1d3\": \"s1d3_filtered_feature_bc_matrix.h5\",\n}\nadatas = {}\n\nfor sample_id, filename in samples.items():\n    path = EXAMPLE_DATA.fetch(filename)\n    sample_adata = sc.read_10x_h5(path)\n    sample_adata.var_names_make_unique()\n    adatas[sample_id] = sample_adata\n\nadata = ad.concat(adatas, label=\"sample\")\nadata.obs_names_make_unique()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/haekyungim/miniconda3/envs/scanpy-tutorial/lib/python3.9/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n  utils.warn_names_duplicates(\"var\")\n/Users/haekyungim/miniconda3/envs/scanpy-tutorial/lib/python3.9/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n  utils.warn_names_duplicates(\"var\")\n/Users/haekyungim/miniconda3/envs/scanpy-tutorial/lib/python3.9/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n  utils.warn_names_duplicates(\"var\")\n/Users/haekyungim/miniconda3/envs/scanpy-tutorial/lib/python3.9/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n  utils.warn_names_duplicates(\"var\")\n/Users/haekyungim/miniconda3/envs/scanpy-tutorial/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n```\n:::\n:::\n\n\nThe data contains 8,785 cells and 36,601 measured genes. This tutorial includes a basic preprocessing and clustering workflow. \n\n## Quality Control\n\nThe scanpy function {func}`~scanpy.pp.calculate_qc_metrics` calculates common quality control (QC) metrics, which are largely based on `calculateQCMetrics` from scater {cite}`McCarthy2017`. One can pass specific gene population to {func}`~scanpy.pp.calculate_qc_metrics` in order to calculate proportions of counts for these populations. Mitochondrial, ribosomal and hemoglobin genes are defined by distinct prefixes as listed below. \n\n::: {#46cba2fe .cell execution_count=6}\n``` {.python .cell-code}\n# mitochondrial genes\nadata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")  # \"MT-\" for human, \"Mt-\" for mouse\n# ribosomal genes\nadata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n# hemoglobin genes\nadata.var[\"hb\"] = adata.var_names.str.contains(\"^HB[^(P)]\")\n```\n:::\n\n\n::: {#ae67c358 .cell execution_count=7}\n``` {.python .cell-code}\nsc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, log1p=True)\n```\n:::\n\n\nOne can now inspect violin plots of some of the computed QC metrics:\n\n* the number of genes expressed in the count matrix\n* the total counts per cell\n* the percentage of counts in mitochondrial genes\n\n::: {#33261a47 .cell execution_count=8}\n``` {.python .cell-code}\nsc.pl.violin(adata, [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"], jitter=0.4, multi_panel=True)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-9-output-1.png){width=751 height=238}\n:::\n:::\n\n\nAdditionally, it is useful to consider QC metrics jointly by inspecting a scatter plot colored by `pct_counts_mt`. \n\n::: {#ad0fcd3b .cell execution_count=9}\n``` {.python .cell-code}\nsc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-10-output-1.png){width=209 height=198}\n:::\n:::\n\n\nBased on the QC metric plots, one could now remove cells that have too many mitochondrial genes expressed or too many total counts by setting manual or automatic thresholds. However, it proved to be beneficial to apply a very permissive filtering strategy in the beginning for your single-cell analysis and filter low quality cells during clustering or revisit the filtering again at a later point. We therefore now only filter cells with less than 100 genes expressed and genes that are detected in less than 3 cells. \n\nAdditionally, it is important to note that for datasets with multiple batches, quality control should be performed for each sample individually as quality control thresholds can very substantially between batches. \n\n::: {#ede26145 .cell execution_count=10}\n``` {.python .cell-code}\nsc.pp.filter_cells(adata, min_genes=100)\nsc.pp.filter_genes(adata, min_cells=3)\n```\n:::\n\n\n### Doublet detection\n\nAs a next step, we run a doublet detection algorithm. Identifying doublets is crucial as they can lead to misclassifications or distortions in downstream analysis steps. Scanpy contains the doublet detection method Scrublet {cite}`Wolock2019`. Scrublet predicts cell doublets using a nearest-neighbor classifier of observed transcriptomes and simulated doublets. {func}`scanpy.pp.scrublet` adds `doublet_score` and `predicted_doublet` to `.obs`. One can now either filter directly on `predicted_doublet` or use the `doublet_score` later during clustering to filter clusters with high doublet scores. \n\n::: {#cc2245f6 .cell execution_count=11}\n``` {.python .cell-code}\nsc.pp.scrublet(adata, batch_key=\"sample\")\n```\n:::\n\n\n:::{seealso}\nAlternative methods for doublet detection within the scverse ecosystem are [DoubletDetection](https://github.com/JonathanShor/DoubletDetection) and [SOLO](https://docs.scvi-tools.org/en/stable/user_guide/models/solo.html). You can read more about these in the [Doublet Detection chapter](https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#doublet-detection) of Single Cell Best Practices.\n:::\n\n## Normalization\n\nThe next preprocessing step is normalization. A common approach is count depth scaling with subsequent log plus one (log1p) transformation. Count depth scaling normalizes the data to a “size factor” such as the median count depth in the dataset, ten thousand (CP10k) or one million (CPM, counts per million). The size factor for count depth scaling can be controlled via `target_sum` in `pp.normalize_total`. We are applying median count depth normalization with log1p transformation (AKA log1PF).\n\n::: {#40ec40e5 .cell execution_count=12}\n``` {.python .cell-code}\n# Saving count data\nadata.layers[\"counts\"] = adata.X.copy()\n```\n:::\n\n\n::: {#f816ebdc .cell execution_count=13}\n``` {.python .cell-code}\n# Normalizing to median total counts\nsc.pp.normalize_total(adata)\n# Logarithmize the data:\nsc.pp.log1p(adata)\n```\n:::\n\n\n## Feature selection\n\nAs a next step, we want to reduce the dimensionality of the dataset and only include the most informative genes. This step is commonly known as feature selection. The scanpy function `pp.highly_variable_genes` annotates highly variable genes by reproducing the implementations of Seurat {cite}`Satija2015`, Cell Ranger {cite}`Zheng2017`, and Seurat v3 {cite}`stuart2019comprehensive` depending on the chosen `flavor`. \n\n::: {#4522aa8d .cell execution_count=14}\n``` {.python .cell-code}\nsc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key=\"sample\")\n```\n:::\n\n\n::: {#1478a089 .cell execution_count=15}\n``` {.python .cell-code}\nsc.pl.highly_variable_genes(adata)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-16-output-1.png){width=357 height=187}\n:::\n:::\n\n\n## Dimensionality Reduction\nReduce the dimensionality of the data by running principal component analysis (PCA), which reveals the main axes of variation and denoises the data.\n\n::: {#d3af7e7e .cell execution_count=16}\n``` {.python .cell-code}\nsc.tl.pca(adata)\n```\n:::\n\n\nLet us inspect the contribution of single PCs to the total variance in the data. This gives us information about how many PCs we should consider in order to compute the neighborhood relations of cells, e.g. used in the clustering function {func}`~scanpy.tl.leiden` or {func}`~scanpy.tl.tsne`. In our experience, often a rough estimate of the number of PCs does fine.\n\n::: {#abe542e3 .cell execution_count=17}\n``` {.python .cell-code}\nsc.pl.pca_variance_ratio(adata, n_pcs=50, log=True)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-18-output-1.png){width=183 height=200}\n:::\n:::\n\n\n## Visualization\n\nLet us compute the neighborhood graph of cells using the PCA representation of the data matrix.\n\n::: {#3d638a63 .cell execution_count=18}\n``` {.python .cell-code}\nsc.pp.neighbors(adata)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/haekyungim/miniconda3/envs/scanpy-tutorial/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n```\n:::\n:::\n\n\nWe suggest embedding the graph in two dimensions using UMAP (McInnes et al., 2018), see below. \n\n::: {#5e889de7 .cell execution_count=19}\n``` {.python .cell-code}\nsc.tl.umap(adata)\n```\n:::\n\n\nWe can now visualize the UMAP according to the `sample`. \n\n::: {#712c8ab0 .cell execution_count=20}\n``` {.python .cell-code}\nsc.pl.umap(adata, color=\"sample\")\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-21-output-1.png){width=216 height=184}\n:::\n:::\n\n\nEven though the data considered in this tutorial includes two different samples, we only observe a minor batch effect and we can continue with clustering and annotation of our data. \n\nIf you inspect batch effects in your UMAP it can be beneficial to integrate across samples and perform batch correction/integration. \n\n## Clustering\n\nAs with Seurat and many other frameworks, we recommend the Leiden graph-clustering method (community detection based on optimizing modularity) {cite}`traag2019louvain`. Note that Leiden clustering directly clusters the neighborhood graph of cells, which we already computed in the previous section.\n\n::: {#59577a1a .cell execution_count=21}\n``` {.python .cell-code}\nsc.tl.leiden(adata, flavor=\"igraph\")\n```\n:::\n\n\n::: {#10f9117f .cell execution_count=22}\n``` {.python .cell-code}\nsc.pl.umap(adata, color=[\"leiden\"])\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-23-output-1.png){width=243 height=187}\n:::\n:::\n\n\n## Re-assess quality control and cell filtering \n\nAs indicated before, we will now re-assess our filtering strategy by visualizing different QC metrics using UMAP. \n\n::: {#4bf24d75 .cell execution_count=23}\n``` {.python .cell-code}\nadata.obs[\"predicted_doublet\"] = adata.obs[\"predicted_doublet\"].astype(\"category\")\nsc.pl.umap(\n    adata,\n    color=[\"leiden\", \"predicted_doublet\", \"doublet_score\"],\n    # increase horizontal space between panels\n    wspace=0.5,\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-24-output-1.png){width=747 height=187}\n:::\n:::\n\n\nWe can now subset the AnnData object to exclude cells predicted as doublets: \n\n::: {#df63bce3 .cell execution_count=24}\n``` {.python .cell-code}\nadata = adata[~adata.obs[\"predicted_doublet\"].to_numpy()].copy()\n```\n:::\n\n\n::: {#8236bd81 .cell execution_count=25}\n``` {.python .cell-code}\nsc.pl.umap(\n    adata, color=[\"leiden\", \"log1p_total_counts\", \"pct_counts_mt\", \"log1p_n_genes_by_counts\"], wspace=0.5, ncols=2\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-26-output-1.png){width=504 height=365}\n:::\n:::\n\n\n## Cell-type annotation\n\n::: {#2f56bb5d .cell execution_count=26}\n``` {.python .cell-code}\ntry: \n    import celltypist as ct\nexcept ImportError:\n    %pip install celltypist\n    import celltypist as ct\ntry:\n    import decoupler as dc\nexcept ImportError:\n    %pip install decoupler\n    import decoupler as dc\n```\n:::\n\n\nWe have now reached a point where we have obtained a set of cells with decent quality, and we can proceed to their annotation to known cell types. Typically, this is done using genes that are exclusively expressed by a given cell type, or in other words these genes are the marker genes of the cell types, and are thus used to distinguish the heterogeneous groups of cells in our data. Previous efforts have collected and curated various marker genes into available resources, such as [CellMarker](http://bio-bigdata.hrbmu.edu.cn/CellMarker/), [TF-Marker](http://bio.liclab.net/TF-Marker/), and [PanglaoDB](https://panglaodb.se/).\n\nCommonly and classically, cell type annotation uses those marker genes subsequent to the grouping of the cells into clusters. So, let's generate a set of clustering solutions which we can then use to annotate our cell types. Here, we will use the Leiden clustering algorithm which will extract cell communities from our nearest neighbours graph.\n\n::: {#b47a7303 .cell execution_count=27}\n``` {.python .cell-code}\nsc.tl.leiden(adata, flavor=\"igraph\", key_added=\"leiden_res0_02\", resolution=0.02)\nsc.tl.leiden(adata, flavor=\"igraph\", key_added=\"leiden_res0_5\", resolution=0.5)\nsc.tl.leiden(adata, flavor=\"igraph\", key_added=\"leiden_res2\", resolution=2)\n```\n:::\n\n\nNotably, the number of clusters that we define is largely arbitrary, and so is the `resolution` parameter that we use to control for it. As such, the number of clusters is ultimately bound to the stable and biologically-meaningful groups that we can ultimately distringuish, typically done by experts in the corresponding field or by using expert-curated prior knowledge in the form of markers.\n\n::: {#2916832f .cell execution_count=28}\n``` {.python .cell-code}\nsc.pl.umap(\n    adata,\n    color=[\"leiden_res0_02\", \"leiden_res0_5\", \"leiden_res2\"],\n    legend_loc=\"on data\",\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-29-output-1.png){width=583 height=186}\n:::\n:::\n\n\nThough UMAPs should not be over-interpreted, here we can already see that in the highest resolution our data is over-clustered, while the lowest resolution is likely grouping cells which belong to distinct cell identities.\n\n### Marker gene set\n\nLet's define a set of marker genes for the main cell types that we expect to see in this dataset. These were adapted from [Single Cell Best Practices annotation chapter](https://www.sc-best-practices.org/cellular_structure/annotation.html), for a more detailed overview and best practices in cell type annotation, we refer the user to it.\n\n::: {#75f2c96b .cell execution_count=29}\n``` {.python .cell-code}\nmarker_genes = {\n    \"CD14+ Mono\": [\"FCN1\", \"CD14\"],\n    \"CD16+ Mono\": [\"TCF7L2\", \"FCGR3A\", \"LYN\"],\n    # Note: DMXL2 should be negative\n    \"cDC2\": [\"CST3\", \"COTL1\", \"LYZ\", \"DMXL2\", \"CLEC10A\", \"FCER1A\"],\n    \"Erythroblast\": [\"MKI67\", \"HBA1\", \"HBB\"],\n    # Note HBM and GYPA are negative markers\n    \"Proerythroblast\": [\"CDK6\", \"SYNGR1\", \"HBM\", \"GYPA\"],\n    \"NK\": [\"GNLY\", \"NKG7\", \"CD247\", \"FCER1G\", \"TYROBP\", \"KLRG1\", \"FCGR3A\"],\n    \"ILC\": [\"ID2\", \"PLCG2\", \"GNLY\", \"SYNE1\"],\n    \"Naive CD20+ B\": [\"MS4A1\", \"IL4R\", \"IGHD\", \"FCRL1\", \"IGHM\"],\n    # Note IGHD and IGHM are negative markers\n    \"B cells\": [\"MS4A1\", \"ITGB1\", \"COL4A4\", \"PRDM1\", \"IRF4\", \"PAX5\", \"BCL11A\", \"BLK\", \"IGHD\", \"IGHM\"],\n    \"Plasma cells\": [\"MZB1\", \"HSP90B1\", \"FNDC3B\", \"PRDM1\", \"IGKC\", \"JCHAIN\"],\n    \"Plasmablast\": [\"XBP1\", \"PRDM1\", \"PAX5\"],  # Note PAX5 is a negative marker\n    \"CD4+ T\": [\"CD4\", \"IL7R\", \"TRBC2\"],\n    \"CD8+ T\": [\"CD8A\", \"CD8B\", \"GZMK\", \"GZMA\", \"CCL5\", \"GZMB\", \"GZMH\", \"GZMA\"],\n    \"T naive\": [\"LEF1\", \"CCR7\", \"TCF7\"],\n    \"pDC\": [\"GZMB\", \"IL3RA\", \"COBLL1\", \"TCF4\"],\n}\n```\n:::\n\n\n::: {#7116c1d2 .cell execution_count=30}\n``` {.python .cell-code}\ndef group_max(adata: sc.AnnData, groupby: str) -> str:\n    import pandas as pd\n\n    agg = sc.get.aggregate(adata, by=groupby, func=\"mean\")\n    return pd.Series(agg.layers[\"mean\"].sum(1), agg.obs[groupby]).idxmax()\n```\n:::\n\n\n::: {#09719b54 .cell execution_count=31}\n``` {.python .cell-code}\nsc.pl.dotplot(adata, marker_genes, groupby=\"leiden_res0_02\")\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-32-output-1.png){width=1105 height=178}\n:::\n:::\n\n\nHere, we can see that cluster {eval}`group_max(adata[:, marker_genes[\"NK\"]], \"leiden_res0_02\")` perhaps contains an admixture of monocytes and dendritic cells, while in cluster {eval}`group_max(adata[:, marker_genes[\"B cells\"]], \"leiden_res0_02\")` we have different populations of B lymphocytes. Thus, we should perhaps consider a higher clustering resolution.\n\n::: {#b00803fb .cell execution_count=32}\n``` {.python .cell-code}\nsc.pl.dotplot(adata, marker_genes, groupby=\"leiden_res0_5\")\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-33-output-1.png){width=1109 height=311}\n:::\n:::\n\n\nThis seems like a resolution that suitable to distinguish most of the different cell types in our data. Ideally, one would look specifically into each cluster, and attempt to subcluster those if required.\n\n### Automatic label prediction\n\nIn addition to using marker collections to annotate our labels, there exist approaches to automatically annotate scRNA-seq datasets. One such tool is [CellTypist](https://github.com/Teichlab/celltypist), which uses gradient-descent optimised logistic regression classifiers to predict cell type annotations.\n\nFirst, we need to retrive the CellTypist models that we wish to use, in this case we will use models with immune cell type and subtype populations generated using 20 tissues from 18 studies ([Domínguez Conde, et al. 2022](https://www.science.org/doi/full/10.1126/science.abl5197)). \n\n::: {#7e90550e .cell execution_count=33}\n``` {.python .cell-code}\nif first_time:\n    ct.models.download_models(model=[\"Immune_All_Low.pkl\"], force_update=True)\n```\n:::\n\n\nThen we predict the major cell type annotations. In this case we will enable `majority_voting`, which will assign a label to the clusters that we obtained previously.\n\n::: {#721330f3 .cell execution_count=34}\n``` {.python .cell-code}\nmodel = ct.models.Model.load(model=\"Immune_All_Low.pkl\")\npredictions = ct.annotate(adata, model=\"Immune_All_Low.pkl\", majority_voting=True, over_clustering=\"leiden_res0_5\")\n# convert back to anndata||\nadata = predictions.to_adata()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n⚠️ Warning: invalid expression matrix, expect ALL genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n🔬 Input data has 16828 cells and 23427 genes\n🔗 Matching reference genes in the model\n🧬 5852 features used for prediction\n⚖️ Scaling input data\n🖋️ Predicting labels\n✅ Prediction done!\n🗳️ Majority voting the predictions\n✅ Majority voting done!\n```\n:::\n:::\n\n\nLet's examine the results of automatic clustering:\n\n::: {#631cd07e .cell execution_count=35}\n``` {.python .cell-code}\nsc.pl.umap(adata, color=\"majority_voting\", ncols=1)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-36-output-1.png){width=297 height=184}\n:::\n:::\n\n\nNote that our previously 'Unknown' cluster is now assigned as 'Pro-B cells'.\n\n### Annotation with enrichment analysis\n\nAutomatic cell type labelling with methods that require pre-trained models will not always work as smoothly, as such classifiers need to be trained on and be representitive for a given tissue and the cell types within it. So, as a more generalizable approach to annotate the cells, we can also use the marker genes from any database, for example [PanglaoDB](https://panglaodb.se/). Here we will use it with simple multi-variate linear regression, implemented in [decoupler](https://github.com/saezlab/decoupler-py). Essentially, this will test if any collection of genes are enriched in any of the cells. Ultimately, this approach is similar to many other marker-based classifiers.\n\nLet's get canonical cell markers using with [decoupler](https://github.com/saezlab/decoupler-py) which queries the OmniPath metadata-base to obtain the [PanglaoDB](https://panglaodb.se/) marker gene database with cannonical cell type markers.\n\n::: {#02ea82c9 .cell execution_count=36}\n``` {.python .cell-code}\n# Query Omnipath and get PanglaoDB\nmarkers = dc.get_resource(name=\"PanglaoDB\", organism=\"human\")\n\n# Print initial information about the markers DataFrame\nprint(\"Initial markers DataFrame shape:\", markers.shape)\n\n# Convert canonical_marker to boolean - fixing the conversion\nmarkers[\"canonical_marker\"] = markers[\"canonical_marker\"].astype(str).map({'True': True, 'False': False})\n\n# Keep canonical cell type markers alone\nmarkers = markers[markers[\"canonical_marker\"] == True]\nprint(\"\\nShape after filtering canonical markers:\", markers.shape)\n\n# Remove duplicated entries\nmarkers = markers[~markers.duplicated([\"cell_type\", \"genesymbol\"])]\nprint(\"\\nShape after removing duplicates:\", markers.shape)\n\n# Convert gene symbols to uppercase in both datasets to ensure consistent matching\nmarkers[\"genesymbol\"] = markers[\"genesymbol\"].str.upper()\nadata.var_names = adata.var_names.str.upper()\n\n# Print overlap statistics\nprint(\"\\nNumber of unique genes in markers:\", len(markers[\"genesymbol\"].unique()))\nprint(\"Number of genes in adata:\", adata.n_vars)\nprint(\"Number of overlapping genes:\", len(set(markers[\"genesymbol\"].unique()) & set(adata.var_names)))\n\n# Print some example cell types and their marker counts\nprint(\"\\nNumber of markers per cell type:\")\nprint(markers.groupby(\"cell_type\")[\"genesymbol\"].count().sort_values(ascending=False).head())\n\n# Run MLM with a lower min_n value\ndc.run_mlm(mat=adata, net=markers, weight=None, source=\"cell_type\", target=\"genesymbol\", verbose=True, use_raw=False, min_n=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInitial markers DataFrame shape: (8461, 14)\n\nShape after filtering canonical markers: (5527, 14)\n\nShape after removing duplicates: (5502, 14)\n\nNumber of unique genes in markers: 3366\nNumber of genes in adata: 23427\nNumber of overlapping genes: 2424\n\nNumber of markers per cell type:\ncell_type\nEndothelial cells    192\nMacrophages          166\nDendritic cells      147\nMast cells           144\nHepatocytes          135\nName: genesymbol, dtype: int64\nRunning mlm on mat with 16828 samples and 23427 targets for 154 sources.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/2 [00:00<?, ?it/s]\r 50%|█████     | 1/2 [00:03<00:03,  3.56s/it]\r100%|██████████| 2/2 [00:06<00:00,  2.92s/it]\r100%|██████████| 2/2 [00:06<00:00,  3.02s/it]\n```\n:::\n:::\n\n\nThe obtained results are stored in the .obsm key, with `mlm_estimate` representing coefficient t-values:\n\n::: {#21c4f0b3 .cell execution_count=37}\n``` {.python .cell-code}\nadata.obsm[\"mlm_estimate\"].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acinar cells</th>\n      <th>Adipocyte progenitor cells</th>\n      <th>Adipocytes</th>\n      <th>Adrenergic neurons</th>\n      <th>Airway epithelial cells</th>\n      <th>Airway goblet cells</th>\n      <th>Alpha cells</th>\n      <th>Alveolar macrophages</th>\n      <th>Anterior pituitary gland cells</th>\n      <th>Astrocytes</th>\n      <th>...</th>\n      <th>T regulatory cells</th>\n      <th>Tanycytes</th>\n      <th>Taste receptor cells</th>\n      <th>Thymocytes</th>\n      <th>Trichocytes</th>\n      <th>Trigeminal neurons</th>\n      <th>Trophoblast cells</th>\n      <th>Trophoblast progenitor cells</th>\n      <th>Tuft cells</th>\n      <th>Urothelial cells</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AAACCCAAGGATGGCT-1</th>\n      <td>-0.829379</td>\n      <td>-0.192387</td>\n      <td>-0.433855</td>\n      <td>-0.259944</td>\n      <td>0.105843</td>\n      <td>-0.896782</td>\n      <td>0.286354</td>\n      <td>0.445317</td>\n      <td>-0.360782</td>\n      <td>0.482100</td>\n      <td>...</td>\n      <td>-1.861577</td>\n      <td>0.653052</td>\n      <td>-0.914405</td>\n      <td>2.135190</td>\n      <td>-0.409456</td>\n      <td>-0.240998</td>\n      <td>0.870413</td>\n      <td>2.188858</td>\n      <td>1.590695</td>\n      <td>-0.726171</td>\n    </tr>\n    <tr>\n      <th>AAACCCAAGGCCTAGA-1</th>\n      <td>0.305256</td>\n      <td>-0.409719</td>\n      <td>0.115441</td>\n      <td>-0.659562</td>\n      <td>-0.503354</td>\n      <td>-0.793676</td>\n      <td>0.980069</td>\n      <td>-3.680857</td>\n      <td>-0.313018</td>\n      <td>1.018442</td>\n      <td>...</td>\n      <td>-1.191339</td>\n      <td>-0.122365</td>\n      <td>-0.713158</td>\n      <td>-0.302480</td>\n      <td>-0.585186</td>\n      <td>0.926535</td>\n      <td>-0.557362</td>\n      <td>-0.477797</td>\n      <td>2.051256</td>\n      <td>-1.071484</td>\n    </tr>\n    <tr>\n      <th>AAACCCAAGTGAGTGC-1</th>\n      <td>0.367563</td>\n      <td>-0.238991</td>\n      <td>0.066879</td>\n      <td>-0.181742</td>\n      <td>0.530131</td>\n      <td>-0.246711</td>\n      <td>-0.459827</td>\n      <td>-0.713275</td>\n      <td>-0.197698</td>\n      <td>-1.156477</td>\n      <td>...</td>\n      <td>-1.127890</td>\n      <td>-0.514065</td>\n      <td>-0.735793</td>\n      <td>0.894280</td>\n      <td>-0.270854</td>\n      <td>-0.110214</td>\n      <td>2.406705</td>\n      <td>-0.221142</td>\n      <td>1.700772</td>\n      <td>-0.384683</td>\n    </tr>\n    <tr>\n      <th>AAACCCACAAGAGGCT-1</th>\n      <td>-1.453875</td>\n      <td>0.022096</td>\n      <td>-1.493422</td>\n      <td>-0.303853</td>\n      <td>-1.110833</td>\n      <td>-1.383801</td>\n      <td>1.080116</td>\n      <td>0.622730</td>\n      <td>0.170097</td>\n      <td>-1.103424</td>\n      <td>...</td>\n      <td>-1.076105</td>\n      <td>-0.212070</td>\n      <td>-0.546337</td>\n      <td>0.964560</td>\n      <td>-0.583426</td>\n      <td>-0.543244</td>\n      <td>0.502228</td>\n      <td>0.681523</td>\n      <td>3.035343</td>\n      <td>-1.010428</td>\n    </tr>\n    <tr>\n      <th>AAACCCACATCGTGGC-1</th>\n      <td>1.160588</td>\n      <td>-0.435748</td>\n      <td>-1.242875</td>\n      <td>-0.100550</td>\n      <td>-1.379393</td>\n      <td>-0.165989</td>\n      <td>-0.541564</td>\n      <td>-0.351312</td>\n      <td>-0.015558</td>\n      <td>0.188370</td>\n      <td>...</td>\n      <td>1.963929</td>\n      <td>-0.292627</td>\n      <td>1.647266</td>\n      <td>-1.076357</td>\n      <td>-0.191659</td>\n      <td>-0.791095</td>\n      <td>-0.017454</td>\n      <td>-0.156497</td>\n      <td>-0.078420</td>\n      <td>-0.396215</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 154 columns</p>\n</div>\n```\n:::\n:::\n\n\nTo visualize the obtianed scores, we can re-use any of scanpy’s plotting functions. \nFirst though, we will extract them from the adata object.\n\n::: {#6f06449c .cell execution_count=38}\n``` {.python .cell-code}\nacts = dc.get_acts(adata=adata, obsm_key=\"mlm_estimate\")\nsc.pl.umap(\n    acts,\n    color=[\n        \"majority_voting\",\n        \"B cells\",\n        \"T cells\",\n        \"Monocytes\",\n        \"Erythroid-like and erythroid precursor cells\",\n        \"NK cells\",\n    ],\n    wspace=0.5,\n    ncols=3,\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-39-output-1.png){width=745 height=360}\n:::\n:::\n\n\nThese results further confirm the our automatic annotation with Celltypist. In addition, here we can also transfer the max over-representation score estimates to assign a label to each cluster.\n\n::: {#fe5cab66 .cell execution_count=39}\n``` {.python .cell-code}\nmean_enr = dc.summarize_acts(acts, groupby=\"leiden_res0_5\", min_std=1.0)\nannotation_dict = dc.assign_groups(mean_enr)\nadata.obs[\"dc_anno\"] = [annotation_dict[clust] for clust in adata.obs[\"leiden_res0_5\"]]\n```\n:::\n\n\nLet's compare all resulting annotations here\n\n::: {#fd900502 .cell execution_count=40}\n``` {.python .cell-code}\nsc.pl.umap(adata, color=[\"majority_voting\", \"dc_anno\"], ncols=1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n... storing 'dc_anno' as categorical\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-41-output-2.png){width=383 height=360}\n:::\n:::\n\n\nGreat. We can see that the different approaches to annotate the data are largely concordant. Though, these annotations are decent, cell type annotation is laborous and repetitive task, one which typically requires multiple rounds of sublucstering and re-annotation. Nevertheless, we now have a good basis with which we can further proceed with manually refining our annotations. \n\n### Differentially-expressed Genes as Markers\n\nFurthermore, one can also calculate marker genes per cluster and then look up whether we can link those marker genes to any known biology, such as cell types and/or states. This is typically done using simple statistical tests, such as Wilcoxon and t-test, for each cluster vs the rest.\n\n::: {#05b47c1d .cell execution_count=41}\n``` {.python .cell-code}\n# Obtain cluster-specific differentially expressed genes\nsc.tl.rank_genes_groups(adata, groupby=\"leiden_res0_5\")\n# Filter those\nsc.tl.filter_rank_genes_groups(adata, min_fold_change=1.5)\n```\n:::\n\n\nWe can then visualize the top 5 differentially-expressed genes on a dotplot.\n\n::: {#e4d78aee .cell execution_count=42}\n``` {.python .cell-code}\nsc.pl.rank_genes_groups_dotplot(adata, groupby=\"leiden_res0_5\", standard_scale=\"var\", n_genes=5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING: dendrogram data not found (using key=dendrogram_leiden_res0_5). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-43-output-2.png){width=1129 height=286}\n:::\n:::\n\n\nWe see that *LYZ*, *ACT8*, *S100A6*, *S100A4*, and *CST3* are all highly expressed in cluster `3`.\nLet's visualize those at the UMAP space:\n\n::: {#3c4818fb .cell execution_count=43}\n``` {.python .cell-code}\ncluster3_genes = [\"LYZ\", \"ACTB\", \"S100A6\", \"S100A4\", \"CST3\"]\nsc.pl.umap(adata, color=[*cluster3_genes, \"leiden_res0_5\"], legend_loc=\"on data\", frameon=False, ncols=3)\n```\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-44-output-1.png){width=588 height=354}\n:::\n:::\n\n\nSimilarly, we can also generate a Violin plot with the distrubtions of the same genes across the clusters.\n\n::: {#c3a58842 .cell execution_count=44}\n``` {.python .cell-code}\nsc.pl.violin(adata, keys=cluster3_genes[0:3], groupby=\"leiden_res0_5\", multi_panel=True)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nUsing categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](scanpy-basic-scrna-tutorial_files/figure-html/cell-45-output-2.png){width=538 height=190}\n:::\n:::\n\n\n",
    "supporting": [
      "scanpy-basic-scrna-tutorial_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}